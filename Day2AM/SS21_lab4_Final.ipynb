{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SS21_lab4_tmp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacyeSN/SS2021/blob/main/Day2AM/SS21_lab4_tmp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDfPDLpau_cf"
      },
      "source": [
        "# **Image Classification (MNIST)**\n",
        "\n",
        "### **1) MLP model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cRlMcYYu6ch"
      },
      "source": [
        "# 0. Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHl-6D8Pdbi6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23sQEXhSfY4I"
      },
      "source": [
        "# 1. Data Preparation\n",
        "\n",
        "The **MNIST** database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
        "\n",
        "We split the training set into 50k and 10k of training and validation data sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5eGrYmzdbi7"
      },
      "source": [
        "**Data Set**  \n",
        "$$X_{train} \\in \\mathcal{R}^{50000 \\times 784}, Y_{train} \\in \\mathcal{Z}^{50000}$$  \n",
        "$$X_{val} \\in \\mathcal{R}^{10000 \\times 784}, Y_{val} \\in \\mathcal{Z}^{10000}$$  \n",
        "$$X_{test} \\in \\mathcal{R}^{10000 \\times 784}, Y_{test} \\in \\mathcal{Z}^{10000}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p_I2-cI1_rv"
      },
      "source": [
        "### Data loading using dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Nrfa8zdbi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ee3afe-88ca-4185-d8dd-92d8a5952ba2"
      },
      "source": [
        "batch_size = 128\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "test_dataset =  datasets.MNIST('./data', train=False, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
        "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 10000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiquI_Mudbi-"
      },
      "source": [
        "### Inspecting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFkE36wedbi_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "2ae55b7f-840d-45fe-8b3b-088314f707d9"
      },
      "source": [
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)  \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(15, 9))\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x648 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEqtbTROlXuB"
      },
      "source": [
        "# 2. Model Define"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiKvO70NvgXR"
      },
      "source": [
        "### **Linear model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5aw3RapVUqQ"
      },
      "source": [
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim): \n",
        "        super(LinearModel, self).__init__()\n",
        "        self.linear = nn.Linear(in_features=in_dim, out_features=out_dim, bias=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTzivdXvk11"
      },
      "source": [
        "### **MLP model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QIJqnLpVbg9"
      },
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hid_dim, n_layers, act, dropout, use_bn, use_xavier): \n",
        "        super(MLPModel, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.act = act\n",
        "        self.dropout = dropout\n",
        "        self.use_bn = use_bn\n",
        "        self.use_xavier = use_xavier\n",
        "\n",
        "        self.fc = nn.Linear(self.in_dim, self.hid_dim)\n",
        "\n",
        "        self.linears = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        for i in range(self.n_layers-1):\n",
        "            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n",
        "            if self.use_bn:\n",
        "                self.bns.append(nn.BatchNorm1d(self.hid_dim))\n",
        "        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n",
        "\n",
        "        if self.act == 'relu':\n",
        "            self.act = nn.ReLU()\n",
        "        \n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "        if self.use_xavier:\n",
        "            for linear in self.linears:\n",
        "                nn.init.xavier_normal_(linear.weight)\n",
        "                linear.bias.data.fill_(0.01)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc(x))\n",
        "        for i in range(len(self.linears)):\n",
        "            x = self.act(self.linears[i](x))\n",
        "            x = self.bns[i](x)\n",
        "            x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgdSvskSotgI"
      },
      "source": [
        "# 3. Simulation Define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EInws-wPVwbC"
      },
      "source": [
        "def experiment(args):\n",
        "    #model = LinearModel(args.in_dim, args.out_dim)\n",
        "\n",
        "    model = MLPModel(args.in_dim, args.out_dim, args.hid_dim, args.n_layers, args.act, args.dropout, args.use_bn, args.use_xavier)\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    # ====== Loss function ====== #\n",
        "    #criterion = nn.MSELoss()\n",
        "    criterion = nn.CrossEntropyLoss() #Image classification\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "\n",
        "    # ====== Data collection ====== #\n",
        "    list_epoch = [] \n",
        "    list_train_loss = []\n",
        "    list_val_loss = []\n",
        "    list_acc = []\n",
        "    list_acc_epoch = []\n",
        "\n",
        "    # ====== Loop ====== #\n",
        "    for epoch in range(args.epoch):  \n",
        "        \n",
        "        # ====== Train ====== #\n",
        "        model.train() # Set the model be 'train mode' \n",
        "        train_loss = 0 # to sum up each batch\n",
        "        \n",
        "        for input_X, true_y in train_loader:\n",
        "            optimizer.zero_grad() # Initialize the gradient in the optimizer\n",
        "\n",
        "            input_X = input_X.squeeze()\n",
        "            input_X = input_X.view(-1, 784)\n",
        "\n",
        "            pred_y = model(input_X)\n",
        "\n",
        "            loss = criterion(pred_y.squeeze(), true_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss +=loss.item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        list_train_loss.append(train_loss)\n",
        "        list_epoch.append(epoch)\n",
        "\n",
        "        # ====== Validation ====== #\n",
        "        model.eval() # Set the model be 'train mode' \n",
        "        val_loss = 0 # to sum up each batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for input_X, true_y in val_loader:\n",
        "\n",
        "                input_X = input_X.squeeze()\n",
        "                input_X = input_X.view(-1, 784)\n",
        "\n",
        "                pred_y = model(input_X)\n",
        "\n",
        "                loss = criterion(pred_y.squeeze(), true_y)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        list_val_loss.append(val_loss)\n",
        "\n",
        "        # ====== Evaluation ====== #\n",
        "        model.eval() # Set the model be 'train mode' \n",
        "        correct = 0 # to sum up each batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for input_X, true_y in test_loader:\n",
        "\n",
        "                input_X = input_X.squeeze()\n",
        "                input_X = input_X.view(-1, 784)\n",
        "\n",
        "                pred_y = model(input_X).max(1, keepdim=True)[1].squeeze()\n",
        "                correct += pred_y.eq(true_y).sum()\n",
        "\n",
        "            acc = correct.item() / len(test_loader.dataset)\n",
        "            list_acc.append(acc)\n",
        "            list_acc_epoch.append(epoch)\n",
        "        \n",
        "        print('Epoch: {}, Train Loss: {}, Val Loss: {}, Test Acc: {}%'.format(epoch, train_loss, val_loss, acc*100))\n",
        "\n",
        "    return list_epoch, list_train_loss, list_val_loss, list_acc, list_acc_epoch"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq6ubzKudbjB"
      },
      "source": [
        "# 4. Train & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5W5ZaZv9lnv"
      },
      "source": [
        "### Checking GPU availability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecDQnV45DBmY",
        "outputId": "80d3e50a-f5d8-4a07-8d34-893ddd7e6a00"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "xh3plxWEdbjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "35c813b7-5e96-47fc-bd77-58f1e77393ef"
      },
      "source": [
        "ts = time.time()\n",
        "\n",
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "args.in_dim = 784\n",
        "args.out_dim = 10\n",
        "\n",
        "args.hid_dim = 200\n",
        "args.n_layers = 5\n",
        "args.act = 'relu'\n",
        "args.dropout = 0.1\n",
        "args.use_bn = 'True'\n",
        "args.use_xavier = 'True'\n",
        "args.momentum = 0.9\n",
        "\n",
        "args.lr = 0.005\n",
        "args.epoch = 100\n",
        "\n",
        "list_epoch, list_train_loss, list_val_loss, list_acc, list_acc_epoch = experiment(args)\n",
        "\n",
        "te = time.time()\n",
        "\n",
        "print('Elapsed time: {} sec'.format(int(te-ts)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLPModel(\n",
            "  (fc): Linear(in_features=784, out_features=200, bias=True)\n",
            "  (linears): ModuleList(\n",
            "    (0): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
            "  )\n",
            "  (bns): ModuleList(\n",
            "    (0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
            "  (act): ReLU()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Epoch: 0, Train Loss: 0.3503860808775553, Val Loss: 0.13778722588020034, Test Acc: 96.03%\n",
            "Epoch: 1, Train Loss: 0.14137004100529435, Val Loss: 0.10950975336983235, Test Acc: 96.65%\n",
            "Epoch: 2, Train Loss: 0.10420446598526005, Val Loss: 0.08987340578644336, Test Acc: 97.1%\n",
            "Epoch: 3, Train Loss: 0.08545491842033766, Val Loss: 0.08214640607939491, Test Acc: 97.58%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5684485a79ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mlist_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_acc_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-cc11963c2b09>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# to sum up each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Initialize the gradient in the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7McPK7jndbjC"
      },
      "source": [
        "# 5. Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fxQy2tYYdbjF"
      },
      "source": [
        "fig = plt.figure(figsize=(15,5))\n",
        "\n",
        "# ====== Loss Fluctuation ====== #\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(list_epoch, list_train_loss, label='train_loss')\n",
        "ax1.plot(list_epoch, list_val_loss, '--', label='val_loss')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.set_ylim(0, 5)\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "ax1.set_title('epoch vs loss')\n",
        "\n",
        "# ====== Metric Fluctuation ====== #\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(list_acc_epoch, list_acc, marker='x', label='mae metric')\n",
        "\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.set_ylabel('mae')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "ax2.set_title('epoch vs mae')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
